{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Attendance System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image as PILImage\n",
    "import time\n",
    "#import classNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here, the path to the folder containing employee images is set. Each employee's images are stored in subfolders named after their respective employee IDs. The `employee_ids` list will be used to store the IDs of all employees detected in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing employee images\n",
    "path = '/Users/avantika/Desktop/zidio/images'  \n",
    "employee_images = {}\n",
    "employee_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load existing attendance records (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    entry_df = pd.read_excel('entry_attendance.xlsx')\n",
    "except FileNotFoundError:\n",
    "    entry_df = pd.DataFrame(columns=['Employee ID', 'Date', 'Entry Time'])\n",
    "\n",
    "try:\n",
    "    exit_df = pd.read_excel('exit_attendance.xlsx')\n",
    "except FileNotFoundError:\n",
    "    exit_df = pd.DataFrame(columns=['Employee ID', 'Date', 'Exit Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we loop through all the employee folders and loads images for each employee. Each folder is named after the employee's ID, and the images inside are used to create a known face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all images for each employee \n",
    "for employee_folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, employee_folder)\n",
    "    \n",
    "    if os.path.isdir(folder_path):  \n",
    "        employee_ids.append(employee_folder)\n",
    "        employee_images[employee_folder] = []\n",
    "        \n",
    "        for image_file in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            employee_images[employee_folder].append(image_path)\n",
    "\n",
    "classNames = employee_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, `findEncodings()`, processes each employee's images to generate face encodings, which will be used to recognize employees based on their facial features. The encodings for each employee's images are averaged to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to find encodings of the images and average them per employee\n",
    "def findEncodings(employee_images):\n",
    "    known_faces = []\n",
    "    \n",
    "    for employee_id, image_paths in employee_images.items():\n",
    "        employee_encodings = []\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            img_encoding = face_recognition.face_encodings(img)\n",
    "            \n",
    "            if img_encoding:  # Only add valid encodings\n",
    "                employee_encodings.append(img_encoding[0])\n",
    "        \n",
    "        # Calculate the average encoding for the employee\n",
    "        if employee_encodings:\n",
    "            avg_encoding = np.mean(employee_encodings, axis=0)\n",
    "            known_faces.append(avg_encoding)\n",
    "        else:\n",
    "            print(f\"No valid face encodings found for Employee ID: {employee_id}\")\n",
    "    \n",
    "    return known_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `markAttendanceEntry()` function logs the entry time of an employee. When a face is recognized, this function records the employee's ID, the current date, and the entry time in an Excel file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mark entry time\n",
    "def markAttendanceEntry(employee_id):\n",
    "    global entry_df\n",
    "    now = datetime.now()\n",
    "    \n",
    "    date_string = now.strftime('%Y-%m-%d')\n",
    "    time_string = now.strftime('%H:%M:%S')\n",
    "    new_entry = pd.DataFrame({'Employee ID': employee_id, 'Date': [date_string], 'Entry Time': [time_string]})\n",
    "    entry_df = pd.concat([entry_df, new_entry], ignore_index=True)\n",
    "    entry_df.to_excel('entry_attendance.xlsx', index=False)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `markAttendanceExit()` function logs the exit time of an employee when they leave the office. Similar to the entry function, this records the employee's ID, the current date, and the exit time in a separate Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mark exit time\n",
    "def markAttendanceExit(employee_id):\n",
    "    global exit_df\n",
    "    now = datetime.now()\n",
    "    date_string = now.strftime('%Y-%m-%d')\n",
    "    time_string = now.strftime('%H:%M:%S')\n",
    "    \n",
    "    new_exit = pd.DataFrame({'Employee ID': employee_id, 'Date': [date_string], 'Exit Time': [time_string]})\n",
    "    exit_df = pd.concat([exit_df, new_exit], ignore_index=True)\n",
    "    exit_df.to_excel('exit_attendance.xlsx', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before capturing attendance records, two DataFrames are initialized to store entry and exit data for employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize attendance DataFrames\n",
    "entry_df = pd.DataFrame(columns=['Employee ID', 'Date', 'Entry Time' ])\n",
    "exit_df = pd.DataFrame(columns=['Employee ID', 'Date', 'Exit Time' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After loading the employee images, the next step is to encode the faces. This process generates unique encodings for each employee's face, which will be used for face recognition during attendance tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding complete!\n"
     ]
    }
   ],
   "source": [
    "# Encode faces from the images folder\n",
    "encodeListKnown = findEncodings(employee_images)\n",
    "print('Encoding complete!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Then we initialize webcam for live video capture. This step allows the program to access the camera and begin capturing frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, a function is defined to display the frames in a user-friendly format. This function ensures that each new frame replaces the previous one, for a smooth viewing experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display video frame in Jupyter\n",
    "def display_frame(frame):\n",
    "    clear_output(wait=True)  # Clear the previous output to avoid stacking frames\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = PILImage.fromarray(frame_rgb)\n",
    "    display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here, it continuously captures video from the webcam, recognizes faces, and records employee attendance based on their entry and exit times. It utilizes the face_recognition library for face detection and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to store IDs of employees whose attendance has been marked\n",
    "employee_last_seen = {}\n",
    "# Run face recognition on webcam feed\n",
    "try:\n",
    "    start_time = time.time()  # Track the starting time\n",
    "    frame_count = 0  # Initialize a frame counter\n",
    "    max_runtime = 0.5\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            print(\"Failed to capture image from webcam\")\n",
    "            break\n",
    "        \n",
    "        imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)  # Resize for faster processing\n",
    "        imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find faces and encodings in the webcam frame\n",
    "        facesCurFrame = face_recognition.face_locations(imgS)\n",
    "        encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "\n",
    "            # Find the best match\n",
    "            matchIndex = np.argmin(faceDis)\n",
    "\n",
    "            if matches[matchIndex]:\n",
    "                employee_id = classNames[matchIndex].upper()\n",
    "\n",
    "                if employee_id not in employee_last_seen:\n",
    "                    markAttendanceEntry(employee_id)  # Record entry time\n",
    "                    employee_last_seen[employee_id] = current_time # Update last seen\n",
    "\n",
    "                # Detect exit (if the employee has been seen earlier and now they reappear, indicating a leave)\n",
    "                elif (current_time - employee_last_seen[employee_id]).seconds > 30:  # 5-minute threshold\n",
    "                    markAttendanceExit(employee_id)  # Record exit time\n",
    "                    print(f\"Logging exit for {employee_id}.\")\n",
    "\n",
    "                    employee_last_seen.pop(employee_id)  # Remove employee from the active list\n",
    "                    print(f'Employee {employee_id} marked as exiting.')\n",
    "\n",
    "                # Draw a box around the face\n",
    "                y1, x2, y2, x1 = faceLoc\n",
    "                y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4  # Scale back to original size\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, employee_id, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Update the display every 5 frames to reduce output clutter\n",
    "        if frame_count % 2 == 0:\n",
    "            display_frame(img)\n",
    "\n",
    "        frame_count += 1  # Increment frame counter\n",
    "\n",
    "        # Check if max runtime is exceeded\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > max_runtime:\n",
    "            print(f\"Stopping after {max_runtime} seconds.\")\n",
    "            break\n",
    "\n",
    "        # Add a break condition to stop the loop in Jupyter\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted by user\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### At the end of the face recognition process, we release the webcam and destroy any OpenCV windows that were created during the execution. This ensures that resources are properly freed and the program exits cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87f5e99d6ed9995c70cde49ee633897dd3a283ce7a67744d82ae4af47685a986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
